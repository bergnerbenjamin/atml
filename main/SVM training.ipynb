{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some startup code\n",
    "\n",
    "import packages needed & load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2825: DtypeWarning: Columns (0,1,2,3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  [['-4.9667664' '-1.8327484' '10.064636' '-0.10971069' '0.048919678'\n",
      "  '0.16738892']\n",
      " ['-5.9427185' '0.6761626999999999' '8.128204' '0.016952515' '-0.003829956'\n",
      "  '-0.02017212']\n",
      " ['-4.6073303' '0.6856842' '7.863983' '-0.59783936' '0.43984985'\n",
      "  '1.1532593']\n",
      " ..., \n",
      " ['-3.371036' '-0.33518824' '3.9647980000000005' '-0.0076358155'\n",
      "  '0.025350908' '-0.0012217305']\n",
      " ['-4.918991' '1.3883362' '9.174178999999999' '0.15565489999999998'\n",
      "  '-0.55152893' '0.47473145']\n",
      " ['0.46183777' '-0.7813720999999999' '9.863296499999999'\n",
      "  '-0.0035552978999999997' '-0.012924193999999998' '0.00041198730000000005']]\n",
      "class_labels:  ['3' '2' '4' ..., '3' '0' '1']\n",
      "features:  [[-5.4779334 -0.9959879 8.149861999999999 -1.3838496999999998 2.047961\n",
      "  -0.48869026]\n",
      " [4.0462008 1.650802 8.422802 -0.0073394775 -0.009567261 0.027053833]\n",
      " [4.048595 1.6783354 8.444349 -0.0062713623 -0.008499145500000001\n",
      "  0.029190063]\n",
      " ..., \n",
      " [-6.2378845 0.29411316 9.556427 0.11271837 0.06685029 0.06026285]\n",
      " [-5.0560303 -0.056991577 6.5452575999999985 -0.02634975 -0.0065874374\n",
      "  -0.0041476456]\n",
      " [-6.0438843 0.92967224 8.168671 -0.31278127 0.048307873 0.36840853]]\n",
      "class_labels:  [4 1 1 ..., 4 5 3]\n",
      "training data  : 49999 rows\n",
      "evaluation data: 44511 rows\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets, preprocessing\n",
    "import numpy as np\n",
    "from loaddata import get_instances_from_csv\n",
    "from startEvaluation import evaluation\n",
    "\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "DATAPATH = \"../sub_datasets/subset_0.csv\"\n",
    "\n",
    "training_data = get_instances_from_csv(DATAPATH, \"train\", numrows=50000)\n",
    "eval_data = get_instances_from_csv(DATAPATH,\"eval\", numrows=500000)\n",
    "print(\"training data  : %s rows\"%training_data[0].shape[0])\n",
    "print(\"evaluation data: %s rows\"%eval_data[0].shape[0])\n",
    "\n",
    "kernels = ['rbf', 'linear', 'sigmoid', 'poly']\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(training_data[0])\n",
    "\n",
    "def print_prediction(training_data, eval_data, *args, **kwargs):\n",
    "\n",
    "    print(\"start training\")\n",
    "    svc = svm.SVC(*args, **kwargs).fit(training_data[0], training_data[1])\n",
    "    print(\"finished training svm %s\"%svc)\n",
    "    evt = evaluation(training_data[1], svc.predict(training_data[0]))\n",
    "    print(\"accuracy on traning data:\")\n",
    "    evt.print_only_accuracy()\n",
    "    eve = evaluation(eval_data[1], svc.predict(eval_data[0]))\n",
    "    print(\"accuracy on evaluation data:\")\n",
    "    eve.print_only_accuracy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic SVM\n",
    "As you can see the print_prediction function fits the SVM-Model to the training data and prints a very simple evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "finished training svm SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "accuracy on traning data:\n",
      "0.877277545551\n",
      "accuracy on evaluation data:\n",
      "0.539625436462\n"
     ]
    }
   ],
   "source": [
    "print_prediction(training_data, eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Lets use different kernels and see how the perform\n",
    "Currently there are 3 Kernels implemented by sklearn that we can test. (Of course we could also implement own kernels later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "start training\n",
      "finished training svm SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "accuracy on traning data:\n",
      "0.656450463293\n",
      "accuracy on evaluation data:\n",
      "0.539625436462\n",
      "linear\n",
      "start training\n",
      "finished training svm SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "accuracy on traning data:\n",
      "0.553215434756\n",
      "accuracy on evaluation data:\n",
      "0.522657214404\n",
      "sigmoid\n",
      "start training\n",
      "finished training svm SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "accuracy on traning data:\n",
      "0.477589654873\n",
      "accuracy on evaluation data:\n",
      "0.447910274045\n"
     ]
    }
   ],
   "source": [
    "for kernel in kernels:\n",
    "    print(kernel)\n",
    "    print_prediction(training_data, eval_data, kernel=kernel, cache_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RBF kernel seems to perform slightly better then the linear kernel. Both are far better then the sigmoid-kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets also check, if scaling the data improves the classification performance\n",
    "Luckily sklearn also provides features for scaling data, the standart scaling function from sklearn scales the data in a way that variance == 1 and mean == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "start training\n",
      "finished training svm SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "accuracy on traning data:\n",
      "0.499195166796\n",
      "accuracy on evaluation data:\n",
      "0.482528832928\n",
      "linear\n",
      "start training\n",
      "finished training svm SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "accuracy on traning data:\n",
      "0.494204371265\n",
      "accuracy on evaluation data:\n",
      "0.483530843297\n",
      "sigmoid\n",
      "start training\n",
      "finished training svm SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "accuracy on traning data:\n",
      "0.462341526499\n",
      "accuracy on evaluation data:\n",
      "0.446407787536\n"
     ]
    }
   ],
   "source": [
    "training_data_scaled = [scaler.transform(training_data[0]), training_data[1]]\n",
    "eval_data_scaled = [scaler.transform(eval_data[0]), eval_data[1]]\n",
    "for kernel in kernels:\n",
    "    print(kernel)\n",
    "    print_prediction(training_data_scaled, eval_data_scaled, kernel=kernel, cache_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parameter Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for gamma in range(.1, .99, .1):\n",
    "    for kernel in kernels:\n",
    "        print(kernel)\n",
    "        print_prediction(training_data, eval_data, kernel=kernel, cache_size=1000)\n",
    "        \n",
    "for coef0 in range(.1, 2.0, .2):\n",
    "    for kernel in ['poly', 'sigmoid']:\n",
    "        print(kernel)\n",
    "        print_prediction(training_data, eval_data, kernel=kernel, cache_size=1000)\n",
    "        \n",
    "for decision_function_shape in ['ovo', 'ovr']:\n",
    "    for kernel in kernels:\n",
    "        print(kernel)\n",
    "        print_prediction(training_data, eval_data, kernel=kernel, cache_size=1000)\n",
    "        \n",
    "for degree in range(1, 5):\n",
    "    for kernel in ['poly']:\n",
    "        print(kernel)\n",
    "        print_prediction(training_data, eval_data, kernel=kernel, cache_size=1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
